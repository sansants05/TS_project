# TS_project
Проект по предмету TS (ФТиАД)  
Проект подготовили: 
- Володченко Полина
- Мелехина Алина
- Цуканов Александр 
- Хатунцев Сергей 

## Описание пайплайна модели

### 1.Anomaly detection 
Детектор аномалий (выбросов) методом IsolationForest. 
Для исторических данных: очищаем данные от аномалий.
Для режима real-time: определяем, является ли новое значение аномалией (True/False) (если да, то переобучаем модель)

### 2. Change point detection 

Детектор разладок двумя методами:
- SR (Shiryaev–Roberts) 
- CUSUM (Cumulative Sum) 
Для исторических данных: выявляем разладки и отображаем их красным цветом
Для режима real-time: определяем, является ли новое значение разладкой (True/False) (если да, то переключаем модель на ручной режим

### 3. Feature engineering
- Добавление лагов 
- Добавление признаков скользящих окон 
- Добавление сезонных признаков 
- Добавление бинарного признака, который указывает, является ли дата налоговой (на основе переданных дат)
- Добавление макроэкономических признаков из внешнего DataFrame (со стандартизацией данных)

### 4. Feature selection & Stability  
- Отбор признаков 

| Класс             | Категория   | Что делает                                                               | Учитывает нелинейность? |
|-------------------|-------------|---------------------------------------------------------------------------|-------------------------|
| `DefaultMethod`   | **Embedded**| • **LassoCV** зануляет коэффициенты неважных фич<br>• **RandomForestRegressor** использует `feature_importances_` | Частично (деревья в RF) |
| `WrapperMethod`   | **Wrapper** | `RFECV` + `TimeSeriesSplit`: на каждом фолде итеративно удаляет наименее значимые фичи, минимизируя MSE | Зависит от базовой модели (Lasso / Ridge / ElasticNet / RF) |
| `FilterMethod`    | **Filter**  | Расчёт **Transfer Entropy** — измеряет направление и силу информационного потока *X → Balance*, выявляя нелинейные временные связи без обучения модели | **Да** |

- Оценка стабильности 
1. Делим выборку на n_splits временных фолдов (TimeSeriesSplit)
2. На каждом фолде повторяем выбранный метод (default / wrapper / filter) и собираем бинарную матрицу выбора признаков
3. Считаем метрику stability по формуле Nogueira et al., 2018 (значение ∈ [0, 1], чем ближе к 1, тем устойчивее результат)

### 5. Auto ML & Model calibration 
- Метрика для оптимизации  
Для оптимизации была выбрана метрика MAE, потому что она выражается в тех же единицах, что и целевая переменная, а значит однозначно интерпретируется бизнесом (так как удовлетворяет его прямому требованию).  
  
- Калибровка модели   
Базовый цикл переобучения — раз в месяц (первый календарный день). Обоснование: месячный лаг обеспечивает баланс между свежестью модели и затратами на вычисления. Также переобучение модели запускается при нахождении аномалий, а переход в ручное управление осуществляется при concept drift. При переходе на fallback режим от пользователя потребуется подтвердить свои действия.   
   
- Подбор гиперпарамеров 
Подбор модели и гиперпапаремтров осуществляется на основе библиотеки flaml (оптимальное время подбора - 30 минут, проверено эмпирически). При существовании обученной модели и при отсутствии сработавших триггеров осуществляется выгрузка модели при помощи joblib, что позволяет мгновенно загружать последнюю валидную версию без ручного вмешательства.


### 6. Prediction 